# Vision Transformer 

## Vision transfomer
transformerをcomputer visionに適用したもの。  
transformerとはattention機構を用いたdeep learningの手法の一つ。

## Vision transfomerの構成例 
①input layer：入力画像からクラストークンとパッチを出力する  
・パッチに分割する  
　画像を分割した後に一列にフラット化する  
・embedding  
　ベクトル表現にする。一般的には次元を減らす。（ベクトルで類似度を表現できるようにする）  
  学習するパラメータ  
・クラストークンを追加する。  
　ベクトル表現と同じ長さのトークン。学習するパラメータ。 パッチの先頭に結合する。 
・positional embedding  
　パッチの画像がどこに位置するのかを示す。  
　クラストークンとパッチに加算される。  
　ベクトル表現と同じ長さのトークン。学習するパラメータ。  
②Encorder：input layerkが出力したクラストークンとパッチを入力し、クラストークンを出力する  
・複数のEncorder Blockから構成される。  
・Encorder BlockはSelf-AttentionとMLPから構成される。  
③MLP Head   :クラストークンを入力し予測するレイヤー 
から構成される

画像を入力し、encorderに入力する特徴量を出力するinput layerは
1-1 画像を同じサイズのパッチに分割する。  
1-2 パッチを少ない次元で有効な情報を持つベクトルembedding vectorに変換して並べる。
    パッチを変換するembedding layerを学習する  
1-3 embedding vectorにclass tokenを結合する。class tokenは画像全体の情報を持つベクトルとして学習する。 
1-4 positional emmbeddingを加える。(class tokenとemmbedding vectorを結合した次元)

encorder  
2-1 layer norm  
2-2 Multi-Head Self Attention  
2-3 Add (input + 2-2)  
2-4 Layer Norm  
2-5 MLP  
2-6 Add (2-3 + 2-5)  

2-6-1 Liner   
2-6-2 GELU  
2-6-3 Dropout  
2-6-4 Liner  
2-6-5 Dropout  

補足  
2-2 角パッチのembedding vectorの内積同士を計算し、内積の値で重み付した加重和を計算する。

 